{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shear bands:\n",
    "\n",
    "This notebook explores shear band emergence. The models are based on those described in  \n",
    "\n",
    "Spiegelman, Marc, Dave A. May, and Cian R. Wilson. \"On the solvability of incompressible Stokes with viscoplastic rheologies in geodynamics.\" Geochemistry, Geophysics, Geosystems (2016).\n",
    "\t\n",
    "Kaus, Boris JP. \"Factors that control the angle of shear bands in geodynamic numerical models of brittle deformation.\" Tectonophysics 484.1 (2010): 36-47.\n",
    "\n",
    "\n",
    "Lemiale, V., et al. \"Shear banding analysis of plastic models formulated for incompressible viscous flows.\" Physics of the Earth and Planetary Interiors 171.1 (2008): 177-186.\n",
    "\n",
    "\n",
    "Moresi, L., and H-B. Mühlhaus. \"Anisotropic viscous models of large-deformation Mohr–Coulomb failure.\" Philosophical Magazine 86.21-22 (2006): 3287-3305.\n",
    "    \n",
    "    \n",
    "## Scaling\n",
    "\n",
    "For this problem, \n",
    "\n",
    "* we scale velocities by $U_0$, the imposed boundary velocity  (m/s)\n",
    "* viscosities by $10^{22}$ Pa s, and \n",
    "* stresses/pressures by $\\eta_0 U_0/H$, where H is the layer depth (m). \n",
    "\n",
    "### NOTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import underworld as uw\n",
    "import math\n",
    "from underworld import function as fn\n",
    "import glucifer\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import natsort\n",
    "import shutil\n",
    "from easydict import EasyDict as edict\n",
    "import operator\n",
    "import pint\n",
    "import time\n",
    "import operator\n",
    "\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####\n",
    "#Stubborn version number conflicts - For now...\n",
    "#####\n",
    "try:\n",
    "    natsort.natsort = natsort.natsorted\n",
    "except:\n",
    "    natsort.natsort = natsort.natsort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model name and directories\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Model name \n",
    "############\n",
    "\n",
    "#Model letter identifier default\n",
    "Model = \"T\"\n",
    "\n",
    "#Model number identifier default:\n",
    "ModNum = 0\n",
    "\n",
    "#Any isolated letter / integer command line args are interpreted as Model/ModelNum\n",
    "\n",
    "if len(sys.argv) == 1:\n",
    "    ModNum = ModNum \n",
    "elif sys.argv[1] == '-f': #\n",
    "    ModNum = ModNum \n",
    "else:\n",
    "    for farg in sys.argv[1:]:\n",
    "        if not '=' in farg: #then Assume it's a not a paramter argument\n",
    "            try:\n",
    "                ModNum = int(farg) #try to convert everingthing to a float, else remains string\n",
    "            except ValueError:\n",
    "                Model  = farg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Standard output directory setup\n",
    "###########\n",
    "\n",
    "outputPath = \"results\" + \"/\" +  str(Model) + \"/\" + str(ModNum) + \"/\" \n",
    "imagePath = outputPath + 'images/'\n",
    "filePath = outputPath + 'files/'\n",
    "checkpointPath = outputPath + 'checkpoint/'\n",
    "dbPath = outputPath + 'gldbs/'\n",
    "outputFile = 'results_model' + Model + '_' + str(ModNum) + '.dat'\n",
    "\n",
    "if uw.rank()==0:\n",
    "    # make directories if they don't exist\n",
    "    if not os.path.isdir(outputPath):\n",
    "        os.makedirs(outputPath)\n",
    "    if not os.path.isdir(checkpointPath):\n",
    "        os.makedirs(checkpointPath)\n",
    "    if not os.path.isdir(imagePath):\n",
    "        os.makedirs(imagePath)\n",
    "    if not os.path.isdir(dbPath):\n",
    "        os.makedirs(dbPath)\n",
    "    if not os.path.isdir(filePath):\n",
    "        os.makedirs(filePath)\n",
    "\n",
    "        \n",
    "comm.Barrier() #Barrier here so no procs run the check in the next cell too early"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameter dictionaries\n",
    "\n",
    "* Parameters are stored in dictionaries. \n",
    "* If params are passed in as flags to the script, they overwrite \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Store the physical parameters, scale factors and dimensionless paramters in easyDicts\n",
    "###########\n",
    "\n",
    "#dp : dimensional paramters\n",
    "dp = edict({})\n",
    "dp.depth=30*1e3                #domain depth\n",
    "dp.asthenosphere=dp.depth/4.    #height of isoviscous layer from bottom of model,\n",
    "dp.eta1=1e24\n",
    "dp.eta2=1e21\n",
    "dp.etaMin=1e18\n",
    "dp.U0=0.0025/(3600*24*365)     #m/s \n",
    "dp.rho=2700.                   #kg/m3\n",
    "dp.g=9.81\n",
    "dp.cohesion=100e6              #\n",
    "dp.fa=0.                      #friction angle degrees\n",
    "dp.a=1.                        #fraction of the dynamic pressure to include in the yield function\n",
    "dp.notchWidth = dp.depth/16.\n",
    "\n",
    "\n",
    "\n",
    "#md : Modelling choices and Physics switches\n",
    "md = edict({})        \n",
    "md.refineMesh=False\n",
    "md.stickyAir=False\n",
    "md.aspectRatio=4.\n",
    "md.res=64\n",
    "md.ppc=25\n",
    "md.tol=1e-10\n",
    "md.pen=1e7   #can be False, otherwise this value is used in Penalty formulation\n",
    "md.maxIts=50\n",
    "md.perturb=0 # 0 for material heterogeneity, 1 for cohesion weakening\n",
    "md.pertSig=1. #sigma for gaussian filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#temp changes, for notebook experimentation\n",
    "#if uw.rank()==0:\n",
    "#    dp.U0*=4.\n",
    "#    dp.fa=0\n",
    "#    md.pertSig=2.\n",
    "#    dp.U0, dp.fa\n",
    "    \n",
    "#if uw.rank()==0: #these should produce a model more like Kaus (2010)\n",
    "#    dp.U0*=0.252 \n",
    "#    dp.asthenosphere=0.0\n",
    "##    dp.notchWidth*=0.33333\n",
    "##    dp.depth*=0.3333\n",
    "#    dp.eta2*=0.1 \n",
    "#    dp.eta1*=10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#If command line args are given, overwrite the above paramter dictionaries \n",
    "###########    \n",
    "\n",
    "\n",
    "###########\n",
    "#If extra arguments are provided to the script\" eg:\n",
    "### >>> uw.py 2 dp.arg1=1 dp.arg2=foo dp.arg3=3.0\n",
    "###\n",
    "###This would assign ModNum = 2, all other values go into the dp dictionary, under key names provided\n",
    "###\n",
    "###Two operators are searched for, = & *=\n",
    "###\n",
    "###If =, parameter is re-assigned to givn value\n",
    "###If *=, parameter is multipled by given value - i.e in-place multiplication\n",
    "###\n",
    "### >>> uw.py 2 dp.arg1=1 dp.arg2=foo dp.arg3*=3.0\n",
    "###########\n",
    "\n",
    "for farg in sys.argv[1:]:\n",
    "    try:\n",
    "        (dicitem,val) = farg.split(\"=\") #Split on equals operator\n",
    "        (dic,arg) = dicitem.split(\".\") #colon notation\n",
    "        if '*=' in farg:\n",
    "            (dicitem,val) = farg.split(\"*=\") #If in-place multiplication, split on '*='\n",
    "            (dic,arg) = dicitem.split(\".\")\n",
    "            \n",
    "        if val == 'True': \n",
    "            val = True\n",
    "        elif val == 'False':     #First check if args are boolean\n",
    "            val = False\n",
    "        else:\n",
    "            try:\n",
    "                val = float(val) #next try to convert  to a float,\n",
    "            except ValueError:\n",
    "                pass             #otherwise leave as string\n",
    "        #Update the dictionary\n",
    "        if farg.startswith('dp'):\n",
    "            if '*=' in farg:\n",
    "                dp[arg] = dp[arg]*val #multiply parameter by given factor\n",
    "            else:\n",
    "                dp[arg] = val    #or reassign parameter by given value\n",
    "        if farg.startswith('md'):\n",
    "            if '*=' in farg:\n",
    "                md[arg] = md[arg]*val #multiply parameter by given factor\n",
    "            else:\n",
    "                md[arg] = val    #or reassign parameter by given value\n",
    "                \n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "\n",
    "comm.barrier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#In this code block we map the dimensional paramters to dimensionless, through scaling factors\n",
    "\n",
    "#sf : scaling factors\n",
    "\n",
    "sf = edict({})\n",
    "sf.LS = dp.depth\n",
    "sf.eta0 = 1e22\n",
    "sf.vel = 0.0025/(3600*24*365)\n",
    "sf.stress = (sf.eta0*dp.U0)/sf.LS\n",
    "sf.density = sf.LS**3\n",
    "sf.g = dp.g\n",
    "sf.rho = (sf.eta0*dp.U0)/(sf.LS**2*dp.g)\n",
    "\n",
    "#ndp : non dimensional parameters\n",
    "ndp = edict({})\n",
    "ndp.depth = dp.depth/sf.LS\n",
    "ndp.U0 = dp.U0/sf.vel\n",
    "ndp.asthenosphere = dp.asthenosphere/sf.LS\n",
    "ndp.eta1 = dp.eta1/sf.eta0\n",
    "ndp.eta2 = dp.eta2/sf.eta0\n",
    "ndp.etaMin = dp.etaMin/sf.eta0\n",
    "ndp.cohesion = (dp.cohesion/sf.stress)*np.cos(np.radians(dp.fa))\n",
    "ndp.fa = math.sin(np.radians(dp.fa)) #friction coefficient\n",
    "ndp.g = dp.g/sf.g\n",
    "ndp.rho = dp.rho/sf.rho\n",
    "ndp.notchWidth = dp.notchWidth/sf.LS\n",
    "ndp.a = dp.a\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('params are:', 1.0, 1.0, 100.0)\n"
     ]
    }
   ],
   "source": [
    "print('params are:', ndp.U0, ndp.depth, ndp.eta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.32550894818\n",
      "-100.0\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stressRatio = (dp.eta1*dp.U0)/(sf.LS**2*dp.g*dp.rho)\n",
    "print(stressRatio )\n",
    "\n",
    "\n",
    "pressure = -(ndp.eta1*ndp.U0)/(ndp.depth)\n",
    "print(pressure)\n",
    "\n",
    "#Lemiale conditions\n",
    "\n",
    "lp1  = (1./np.cos(np.radians(dp.fa)))*(2.*dp.eta1*dp.U0)/(sf.LS) \n",
    "lp2 = np.tan(np.radians(dp.fa))*((2.*dp.eta1*dp.U0)/(sf.LS) - (sf.LS*dp.g*dp.rho))\n",
    "\n",
    "print((lp1+lp2)/dp.cohesion > 1.)\n",
    "\n",
    "print(lp2 < dp.cohesion)\n",
    "lp2/ dp.cohesion\n",
    "\n",
    "\n",
    "#Speigelman heuristic\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mesh and finite element variables\n",
    "------\n",
    "\n",
    "Note: the use of a pressure-sensitive rheology suggests that it is important to use a Q2/dQ1 element "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "minX  = -0.5*md.aspectRatio*ndp.depth\n",
    "maxX  =  0.5*md.aspectRatio*ndp.depth\n",
    "maxY  = ndp.depth\n",
    "meshV =  1.0\n",
    "\n",
    "if md.stickyAir:\n",
    "    maxY  = 1.1\n",
    "\n",
    "\n",
    "resY = int(md.res)\n",
    "resX = int(resY*md.aspectRatio)\n",
    "\n",
    "elementType=\"Q2/dPc1\"  # This is enough for a test but not to use the code in anger\n",
    "\n",
    "mesh = uw.mesh.FeMesh_Cartesian( elementType = (elementType), \n",
    "                                 elementRes  = ( resX, resY), \n",
    "                                 minCoord    = ( minX, 0.), \n",
    "                                 maxCoord    = ( maxX, maxY),\n",
    "                                 periodic    = [False, False]  ) \n",
    "\n",
    "\n",
    "\n",
    "velocityField    = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=mesh.dim )\n",
    "pressureField    = uw.mesh.MeshVariable( mesh=mesh.subMesh, nodeDofCount=1 )\n",
    "\n",
    "velocityField.data[:] = [0.,0.]\n",
    "pressureField.data[:] = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boundary conditions\n",
    "\n",
    "Pure shear with moving  walls — all boundaries are zero traction with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iWalls = mesh.specialSets[\"MinI_VertexSet\"] + mesh.specialSets[\"MaxI_VertexSet\"]\n",
    "jWalls = mesh.specialSets[\"MinJ_VertexSet\"] + mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "base   = mesh.specialSets[\"MinJ_VertexSet\"]\n",
    "top    = mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "\n",
    "allWalls = iWalls + jWalls\n",
    "\n",
    "velocityBCs = uw.conditions.DirichletCondition( variable        = velocityField, \n",
    "                                                indexSetsPerDof = (iWalls, base) )\n",
    "\n",
    "for index in mesh.specialSets[\"MinI_VertexSet\"]:\n",
    "    velocityField.data[index] = [ndp.U0, 0.]\n",
    "for index in mesh.specialSets[\"MaxI_VertexSet\"]:\n",
    "    velocityField.data[index] = [ -ndp.U0, 0.]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the material swarm and passive tracers\n",
    "\n",
    "The material swarm is used for tracking deformation and history dependence of the rheology\n",
    "\n",
    "Passive swarms can track all sorts of things but lack all the machinery for integration and re-population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "swarm  = uw.swarm.Swarm( mesh=mesh )\n",
    "swarmLayout = uw.swarm.layouts.GlobalSpaceFillerLayout( swarm=swarm, particlesPerCell=int(md.ppc) )\n",
    "swarm.populate_using_layout( layout=swarmLayout )\n",
    "\n",
    "# create pop control object\n",
    "pop_control = uw.swarm.PopulationControl(swarm)\n",
    "\n",
    "surfaceSwarm = uw.swarm.Swarm( mesh=mesh )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a particle advection system\n",
    "\n",
    "Note that we need to set up one advector systems for each particle swarm (our global swarm and a separate one if we add passive tracers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "advector        = uw.systems.SwarmAdvector( swarm=swarm,            velocityField=velocityField, order=2 )\n",
    "advector2       = uw.systems.SwarmAdvector( swarm=surfaceSwarm,     velocityField=velocityField, order=2 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add swarm variables\n",
    "\n",
    "We are using a single material with a single rheology. We need to track the plastic strain in order to have some manner of strain-related softening (e.g. of the cohesion or the friction coefficient). For visualisation of swarm data we need an actual swarm variable and not just the computation.\n",
    "\n",
    "Other variables are used to track deformation in the shear band etc.\n",
    "\n",
    "**NOTE**:  Underworld needs all the swarm variables defined before they are initialised or there will be / can be memory problems (at least it complains about them !). That means we need to add the monitoring variables now, even if we don't always need them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tracking different materials\n",
    "\n",
    "materialVariable = swarm.add_variable( dataType=\"int\", count=1 )\n",
    "\n",
    "\n",
    "# plastic deformation for weakening\n",
    "\n",
    "plasticStrain  = swarm.add_variable( dataType=\"double\",  count=1 )\n",
    "\n",
    "\n",
    "\n",
    "# passive markers at the surface\n",
    "\n",
    "surfacePoints = np.zeros((1000,2))\n",
    "surfacePoints[:,0] = np.linspace(minX+0.01, maxX-0.01, 1000)\n",
    "surfacePoints[:,1] = 1.0 #\n",
    "\n",
    "surfaceSwarm.add_particles_with_coordinates( surfacePoints )\n",
    "yvelsurfVar = surfaceSwarm.add_variable( dataType=\"double\", count=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise swarm variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yvelsurfVar.data[...] = (0.)\n",
    "materialVariable.data[...] = 0\n",
    "plasticStrain.data[...] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Material distribution in the domain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialise the 'materialVariable' data to represent different materials. \n",
    "material1 = 1 # viscoplastic\n",
    "material0 = 0 # accommodation layer a.k.a. Sticky Air\n",
    "material2 = 2 # Under layer \n",
    "\n",
    "\n",
    "materialVariable.data[:] = 0.\n",
    "\n",
    "# The particle coordinates will be the input to the function evaluate (see final line in this cell).\n",
    "# We get proxy for this now using the input() function.\n",
    "\n",
    "coord = fn.input()\n",
    "\n",
    "# Setup the conditions list for the following conditional function. Where the\n",
    "# z coordinate (coordinate[1]) is less than the perturbation, set to lightIndex.\n",
    "\n",
    "\n",
    "\n",
    "#notchWidth = (1./32.) * md.notch_fac\n",
    "\n",
    "notchCond = operator.and_(coord[1] < ndp.asthenosphere + ndp.notchWidth, operator.and_(coord[0] < ndp.notchWidth, coord[0] > -1.*ndp.notchWidth )  )\n",
    "\n",
    "mu = ndp.notchWidth\n",
    "sig =  0.25*ndp.notchWidth\n",
    "gausFn1 = ndp.notchWidth*fn.math.exp(-1.*(coord[0] - mu)**2/(2 * sig**2)) + ndp.asthenosphere\n",
    "mu = -1.*ndp.notchWidth\n",
    "gausFn2 = ndp.notchWidth*fn.math.exp(-1.*(coord[0] - mu)**2/(2 * sig**2)) + ndp.asthenosphere\n",
    "\n",
    "conditions = [ (       coord[1] > 1.0 , material0 ), #air\n",
    "               (       coord[1] < ndp.asthenosphere , material2 ), #asthenosphere\n",
    "               (       coord[1] < gausFn1 , material2 ), #asthenosphere\n",
    "               (       coord[1] < gausFn2 , material2 ), #asthenosphere       \n",
    "\n",
    "               (       notchCond , material2 ),\n",
    "               (       True ,           material1 ) ]  #visco-plastic\n",
    "\n",
    "# The actual function evaluation. Here the conditional function is evaluated at the location\n",
    "# of each swarm particle. The results are then written to the materialVariable swarm variable.\n",
    "\n",
    "\n",
    "if md.perturb == 0:\n",
    "    materialVariable.data[:] = fn.branching.conditional( conditions ).evaluate(swarm)\n",
    "    \n",
    "else: \n",
    "    #in this case just build the asphenosphere\n",
    "    materialVariable.data[:] = material1\n",
    "    materialVariable.data[np.where(swarm.particleCoordinates.data[:,1] < ndp.asthenosphere)] = material2\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figMat = glucifer.Figure( figsize=(1200,400), boundingBox=((-2.0, 0.0, 0.0), (2.0, 1.0, 0.0)) )\n",
    "figMat.append( glucifer.objects.Points(swarm,materialVariable, pointSize=2.0) )\n",
    "figMat.append( glucifer.objects.Mesh(mesh))\n",
    "#figMat.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buoyancy forces\n",
    "\n",
    "In this example, no buoyancy forces are included in the Stokes system, the Pressures that appear are dynamic (p'). We add the appropriate lithostatic component to the Drucker-prager yield criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lithPressureFn = ndp.rho* (1. - coord[1])\n",
    "#dynPressure = pressureField - lithPressureFn\n",
    "\n",
    "z_hat = (0., -1.0 )\n",
    "buoyancyFn = z_hat * fn.misc.constant(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rheology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a yield criterion (function)\n",
    "\n",
    "\\begin{equation}\n",
    "    \\tau_\\textrm{yield} = \\cos(\\phi)C(\\varepsilon_p) + \\sin(\\phi(\\varepsilon_p))( p_{lith} + \\alpha P') \n",
    "\\end{equation}\n",
    "\n",
    "The yield strength described above needs to be evaluated on the fly at the particles (integration points). It therefore needs to be a function composed of mesh variables, swarm variables, constants, and mathematical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create a filtered random signal on mesh\n",
    "\n",
    "#from scipy.ndimage.filters import gaussian_filter\n",
    "np.random.seed(2)\n",
    "randomField    = uw.mesh.MeshVariable( mesh=mesh, nodeDofCount=1 )\n",
    "randomField.data[:,0] = np.random.rand(randomField.data.shape[:][0])\n",
    "\n",
    "\n",
    "#this only works in serial atm\n",
    "if uw.nProcs()==1:\n",
    "    from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "    rfdata = randomField.data.copy()\n",
    "    rfdata = rfdata.reshape(2*mesh.elementRes[1] + 1, 2*mesh.elementRes[0] + 1)\n",
    "    #symmetrize\n",
    "    rfdata[:,int(np.ceil((2*mesh.elementRes[0] + 1)/2.)):] = rfdata[:,int(np.floor((2*mesh.elementRes[0] + 1)/2.)):0:-1]\n",
    "\n",
    "    filt = gaussian_filter(rfdata,  sigma=md.pertSig)\n",
    "    #plt.imshow(filt)\n",
    "    randomField.data[:,0] = filt.reshape(randomField.data.shape[:][0])\n",
    "\n",
    "\n",
    "    #normalse the filterd signal\n",
    "    randomField.data[:,0] -= randomField.data[:].min()\n",
    "    randomField.data[:,0] /= randomField.data[:].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figPert = glucifer.Figure( figsize=(1200,400), boundingBox=((-2.0, 0.0, 0.0), (2.0, 1.0, 0.0)) )\n",
    "figPert.append( glucifer.objects.Surface(mesh,randomField) )\n",
    "figPert.append( glucifer.objects.Mesh(mesh))\n",
    "#figPert.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plastic strain - weaken a region at the base close to the boundary (a weak seed but through cohesion softening)\n",
    "\n",
    "def gaussian(xx, centre, width):\n",
    "    return ( np.exp( -(xx - centre)**2 / width ))\n",
    "\n",
    "def boundary(xx, minX, maxX, width, power):\n",
    "    zz = (xx - minX) / (maxX - minX)\n",
    "    return (np.tanh(zz*width) + np.tanh((1.0-zz)*width) - math.tanh(width))**power\n",
    "\n",
    "# weight = boundary(swarm.particleCoordinates.data[:,1], 10, 4) \n",
    "\n",
    "if md.perturb != 0: #build a heterogenity into the cohesion, through the accumulated plastic strain term\n",
    "\n",
    "    #plasticStrain.data[:] = np.random.normal(loc=0.5, scale=0.05,size = plasticStrain.data.shape[:])\n",
    "    plasticStrain.data[:] = randomField.evaluate(swarm)*0.5\n",
    "    #plasticStrain.data[:,0] *= gaussian(swarm.particleCoordinates.data[:,0], 0.0, ndp.notchWidth)\n",
    "    plasticStrain.data[:,0] *= gaussian(swarm.particleCoordinates.data[:,0], 0.0, ndp.notchWidth/2.) \n",
    "    #plasticStrain.data[:,0] *= gaussian(swarm.particleCoordinates.data[:,1], ndp.asthenosphere, ndp.notchWidth/2.) \n",
    "    plasticStrain.data[:,0] *= gaussian(swarm.particleCoordinates.data[:,1], ndp.asthenosphere, ndp.notchWidth/4.) \n",
    "    plasticStrain.data[:,0] *= boundary(swarm.particleCoordinates.data[:,0], minX, maxX, 10.0, 2)\n",
    "    plasticStrain.data[:,0][np.where(swarm.particleCoordinates.data[:,1] < ndp.asthenosphere)] = 0.\n",
    "\n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figMat2 = glucifer.Figure( figsize=(1200,400), boundingBox=((-2.0, 0.0, 0.0), (2.0, 1.0, 0.0)) )\n",
    "figMat2.append( glucifer.objects.Points(swarm,plasticStrain, pointSize=2.0) )\n",
    "figMat2.append( glucifer.objects.Mesh(mesh))\n",
    "#figMat2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#if uw.nProcs() == 1:   # Serial\n",
    "#    xx = np.arange(-2, 2, 0.01)\n",
    "#    yy = boundary(xx, minX, maxX, 10., 2.)\n",
    "#    pyplot.scatter(xx,yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Friction - in this form it can also be made to weaken with strain\n",
    "\n",
    "cohesion0       = fn.misc.constant(ndp.cohesion)\n",
    "cohesionInf = 0.25*cohesion0\n",
    "refStrain = 0.5\n",
    "\n",
    "# Drucker-Prager yield criterion\n",
    "\n",
    "weakenedCohesion = cohesion0+ (cohesionInf - cohesion0)*fn.misc.min(1., plasticStrain/refStrain) \n",
    "\n",
    "yieldStressFn   = weakenedCohesion  + ndp.fa *(lithPressureFn + ndp.a*pressureField ) \n",
    "\n",
    "#yieldStressFn   = cohesionFn + ndp.fa *(lithPressureFn + ndp.a*fn.misc.max(fn.misc.constant(0.), pressureField) ) #in this case only positive dynamic pressures\n",
    "\n",
    "\n",
    "# first define strain rate tensor\n",
    "\n",
    "strainRateFn = fn.tensor.symmetric( velocityField.fn_gradient )\n",
    "strainRate_2ndInvariantFn = fn.tensor.second_invariant(strainRateFn)\n",
    "\n",
    "# now compute a viscosity assuming yielding\n",
    "\n",
    "#min_viscosity = visc0  # same as the air ... \n",
    "\n",
    "yieldingViscosityFn =  0.5 * yieldStressFn / (strainRate_2ndInvariantFn+1.0e-18)\n",
    "\n",
    "#viscosityFn = fn.exception.SafeMaths( fn.misc.max(fn.misc.min(yieldingViscosityFn, \n",
    "#                                                              backgroundViscosityFn), \n",
    "#                                                  min_viscosity))\n",
    "\n",
    "\n",
    "compositeviscosityFn = fn.exception.SafeMaths( fn.misc.max(\n",
    "                                              1./((1./yieldingViscosityFn) + (1./ndp.eta1))\n",
    "                                             , ndp.etaMin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "viscosityMap = { material0: ndp.etaMin, material1:compositeviscosityFn, material2:ndp.eta2 }\n",
    "\n",
    "viscosityFn  = fn.branching.map( fn_key = materialVariable, \n",
    "                                           mapping = viscosityMap )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System setup\n",
    "-----\n",
    "\n",
    "Setup a Stokes equation system and connect a solver up to it.  \n",
    "\n",
    "In this example, no buoyancy forces are considered. However, to establish an appropriate pressure gradient in the material, it would normally be useful to map density from material properties and create a buoyancy force."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#viscosityFn.evaluate(swarm).mean()\n",
    "#velocityField.evaluate(iWalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stokes = uw.systems.Stokes(    velocityField = velocityField, \n",
    "                               pressureField = pressureField,\n",
    "                               conditions    = velocityBCs,\n",
    "                               fn_viscosity  = viscosityFn,\n",
    "                               fn_bodyforce=buoyancyFn)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "solver = uw.systems.Solver( stokes )\n",
    "\n",
    "# \"mumps\" is a good alternative for \"lu\" but  # use \"lu\" direct solve and large penalty (if running in serial)\n",
    "\n",
    "\n",
    "\n",
    "solver.set_inner_method(\"mumps\")\n",
    "if md.pen:          #use penalty method\n",
    "    solver.set_penalty(md.pen) \n",
    "solver.options.scr.ksp_rtol = 1.0e-7\n",
    "solver.options.scr.ksp_rtol = 1.0e-4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Picard iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prevVelocityField    = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=mesh.dim )\n",
    "\n",
    "prevPressureField    = uw.mesh.MeshVariable( mesh=mesh.subMesh,         nodeDofCount=1)\n",
    "\n",
    "\n",
    "prevVelocityField.data[:] = (0., 0.)\n",
    "prevPressureField.data[:] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def volumeint(Fn = 1., rFn=1.):\n",
    "    return uw.utils.Integral( Fn*rFn,  mesh )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#md.maxIts = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "surfaceArea = uw.utils.Integral(fn=1.0,mesh=mesh, integrationType='surface', surfaceIndexSet=top)\n",
    "surfacePressureIntegral = uw.utils.Integral(fn=pressureField, mesh=mesh, integrationType='surface', surfaceIndexSet=top)\n",
    "\n",
    "(area,) = surfaceArea.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#The underworld Picard interation applies the following residual (SystemLinearEquations.c)\n",
    "\n",
    "#/* Calculate Residual */\n",
    "#      VecAXPY( previousVector, -1.0, currentVector );\n",
    "#      VecNorm( previousVector, NORM_2, &prevVecNorm );\n",
    "#      VecNorm( currentVector, NORM_2, &currVecNorm );\n",
    "#      residual = ((double)prevVecNorm) / ((double)currVecNorm);\n",
    "\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "\n",
    "res1Vals = []\n",
    "res2Vals = []\n",
    "res3Vals = []\n",
    "\n",
    "for i in range(int(md.maxIts)):\n",
    "    \n",
    "    prevVelocityField.data[:] = velocityField.data.copy()\n",
    "    prevPressureField.data[:] = pressureField.data[:] \n",
    "\n",
    "    \n",
    "    solver.solve( nonLinearIterate=False)\n",
    "    \n",
    "    #remove drift in the pressure\n",
    "    (p0,) = surfacePressureIntegral.evaluate() \n",
    "    pressureField.data[:] -= p0 / area\n",
    "    \n",
    "    #Update the dynamic pressure variable\n",
    "    #dynPressureField.data[:] = pressureField.data[:] - lithPressureFn.evaluate(mesh.subMesh)\n",
    "    \n",
    "    \n",
    "    ####\n",
    "    #Caluclate a range of norms to assess convergence\n",
    "    ####\n",
    "    \n",
    "    #L2 norm of current velocity\n",
    "    v2 = fn.math.dot(velocityField,  velocityField)\n",
    "    _Vr = volumeint(v2)\n",
    "    velL2 = np.sqrt(_Vr.evaluate()[0])\n",
    "    \n",
    "    \n",
    "    #L2 norm of delta velocity\n",
    "    \n",
    "    delV = velocityField - prevVelocityField\n",
    "    v2 = fn.math.dot(delV,  delV)\n",
    "    _Vr = volumeint(v2)\n",
    "    delvelL2 = np.sqrt(_Vr.evaluate()[0])\n",
    "    \n",
    "    \n",
    "    #L2 norm of current dynamic pressure\n",
    "    p2 = fn.math.dot(pressureField, pressureField)\n",
    "    _Pr = volumeint(p2)\n",
    "    pL2 = np.sqrt(_Pr.evaluate()[0])\n",
    "    \n",
    "    \n",
    "    #L2 norm of delta dynamic pressure\n",
    "    delP = pressureField - prevPressureField\n",
    "    p2 = fn.math.dot(delP,  delP)\n",
    "    _Pr = volumeint(p2)\n",
    "    delpL2 = np.sqrt(_Pr.evaluate()[0])\n",
    "    \n",
    "    #Full norm of the primal variables\n",
    "    \n",
    "    x2 = fn.math.dot(velocityField,  velocityField) + fn.math.dot(pressureField, pressureField)\n",
    "    _Xr = volumeint(x2)\n",
    "    xL2 = np.sqrt(_Xr.evaluate()[0])\n",
    "    \n",
    "    #Full norm of the change in primal variables\n",
    "    \n",
    "    delV = velocityField - prevVelocityField\n",
    "    delP = pressureField - prevPressureField\n",
    "    x2 = fn.math.dot(delV,  delV) + fn.math.dot(delP, delP)\n",
    "    _Xr = volumeint(x2)\n",
    "    delxL2 = np.sqrt(_Xr.evaluate()[0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    res1 = abs(delvelL2 /velL2)\n",
    "    res1Vals .append(res1)\n",
    "    \n",
    "    res2 = abs(delpL2 /pL2)\n",
    "    res2Vals .append(res2)\n",
    "    \n",
    "    res3 = abs(delxL2 /xL2)\n",
    "    res3Vals .append(res3)\n",
    "\n",
    "    \n",
    "    count +=1\n",
    "    print(res1, res2, res3)\n",
    "    print(count)\n",
    "    \n",
    "    \n",
    "    #Converged stopping condition\n",
    "    if res1 < md.tol:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%pylab inline\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.scatter(range(len(resVals)), resVals)\n",
    "#ax.set_yscale('log')\n",
    "#ax.set_ylim(0.0005, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "velocityField.fn_gradient.evaluate(mesh)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#p1 = pressureField\n",
    "#p2 = -((2.0/3.*viscosityFn + ndp.lam) * (velocityField.fn_gradient[0] + velocityField.fn_gradient[3]))\n",
    "#div = (velocityField.fn_gradient[0] + velocityField.fn_gradient[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#[1./i for i in [1.0, 0.8, 0.6, 0.4, 0.2, 0.1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figComp = glucifer.Figure( figsize=(1600,400), boundingBox=((-2.0, 0.0, 0.0), (2.0, 1.0, 0.0)) )\n",
    "figComp.append( glucifer.objects.Points(swarm,p2, pointSize=2.0) )\n",
    "#figComp.append( glucifer.objects.Surface(mesh,div) )\n",
    "#figComp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#figSinv = glucifer.Figure( figsize=(1600,400), boundingBox=((-2.0, 0.0, 0.0), (2.0, 1.0, 0.0)) )\n",
    "figSinv = glucifer.Figure( figsize=(1600,400) )\n",
    "\n",
    "\n",
    "#figSinv .append( glucifer.objects.Points(swarm,plasticStrain, pointSize=2.0) )\n",
    "\n",
    "#figSinv .append( glucifer.objects.Points(swarm,strainRate_2ndInvariantFn, pointSize=2.0, valueRange=[1e-3, 2.]) )\n",
    "figSinv .append( glucifer.objects.Points(swarm,strainRate_2ndInvariantFn, pointSize=2.0) )\n",
    "figSinv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figVisc = glucifer.Figure( figsize=(1600,400), boundingBox=((-2.0, 0.0, 0.0), (2.0, 1.0, 0.0)) )\n",
    "\n",
    "#figVisc.append( glucifer.objects.VectorArrows(mesh, velocityField, arrowHead=0.25, scaling=.075, resolutionI=32, resolutionJ=8) )\n",
    "\n",
    "\n",
    "figVisc.append( glucifer.objects.Points(swarm, viscosityFn, pointSize=2.0, logScale=True ) )\n",
    "#figVisc.append( glucifer.objects.Points(swarm, viscosityFn, pointSize=2.0, logScale=True ,valueRange=[5., 500]) )\n",
    "\n",
    "figVisc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figPres= glucifer.Figure( figsize=(1600,400), boundingBox=((-2.0, 0.0, 0.0), (2.0, 1.0, 0.0)) )\n",
    "\n",
    "#figPres.append( glucifer.objects.Surface(mesh, pressureField))\n",
    "figPres.append( glucifer.objects.Points(swarm, pressureField, pointSize=2.0))\n",
    "#figPres.append( glucifer.objects.Points(swarm, pressureField,pointSize=2.0, valueRange=[-25.,50.] ))\n",
    "\n",
    "#figPres.draw.label(r'$\\sin (x)$', (0.2,0.7,0))\n",
    "#figPres.append( glucifer.objects.Mesh(mesh,opacity=0.2))\n",
    "\n",
    "figPres.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pressureField.data.min() - pressureField.data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#figSinv.save_image(imagePath + \"figSinv.png\")\n",
    "figVisc.save_image(imagePath +  \"figVisc.png\")\n",
    "figPres.save_image(imagePath + \"figPres.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "velocityField.save(filePath + \"vel.h5\")\n",
    "pressureField.save(filePath + \"pressure.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<underworld.utils._utils.SavedFileData at 0x7fbd97b96210>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yvelsurfVar.data[...] = velocityField[1].evaluate(surfaceSwarm)\n",
    "yvelsurfVar.save(filePath + \"yvelsurf.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save points to determine shear band angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eii_mean = uw.utils.Integral(strainRate_2ndInvariantFn,mesh).evaluate()[0]/4.\n",
    "\n",
    "eii_std = uw.utils.Integral(fn.math.sqrt(0.25*(strainRate_2ndInvariantFn - eii_mean)**2.), mesh).evaluate()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grab all of material points that are above 2 sigma of mean strain rate invariant\n",
    "\n",
    "\n",
    "\n",
    "xv, yv = np.meshgrid(\n",
    "        np.linspace(mesh.minCoord[0], mesh.maxCoord[0], mesh.elementRes[0]), \n",
    "        np.linspace(mesh.minCoord[1], mesh.maxCoord[1], mesh.elementRes[1]))\n",
    "\n",
    "meshGlobs = np.row_stack((xv.flatten(), yv.flatten())).T\n",
    "\n",
    "\n",
    "#Calculate the 2-sigma value of the strain rate invariant function (\n",
    "#we use this a definition for a shear band)\n",
    "eII_sig = eii_mean  + 1.5*eii_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shearbandswarm  = uw.swarm.Swarm( mesh=mesh, particleEscape=True )\n",
    "shearbandswarmlayout  = uw.swarm.layouts.GlobalSpaceFillerLayout( swarm=shearbandswarm , particlesPerCell=int(md.ppc/16.) )\n",
    "shearbandswarm.populate_using_layout( layout=shearbandswarmlayout )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#shearbandswarm.particleGlobalCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True], dtype=bool)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(strainRate_2ndInvariantFn.evaluate(shearbandswarm) < eII_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2./1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with shearbandswarm.deform_swarm():\n",
    "    mask = np.where(strainRate_2ndInvariantFn.evaluate(shearbandswarm) < eII_sig)\n",
    "    shearbandswarm.particleCoordinates.data[mask[0]]= (1e20, 1e20)\n",
    "\n",
    "shearbandswarm.update_particle_owners()    \n",
    "\n",
    "with shearbandswarm.deform_swarm():\n",
    "    mask = np.where((shearbandswarm.particleCoordinates.data[:,1] < ndp.asthenosphere + ndp.notchWidth) | \n",
    "                    (shearbandswarm.particleCoordinates.data[:,1] >  1. - ndp.notchWidth) |\n",
    "                    (shearbandswarm.particleCoordinates.data[:,0] <  minX/1.5))\n",
    "    shearbandswarm.particleCoordinates.data[mask]= (1e20, 1e20)\n",
    "\n",
    "shearbandswarm.update_particle_owners()\n",
    "\n",
    "\n",
    "with shearbandswarm.deform_swarm():\n",
    "    mask = np.where(shearbandswarm.particleCoordinates.data[:,0] > -2.*ndp.notchWidth)\n",
    "    shearbandswarm.particleCoordinates.data[mask]= (1e20, 1e20)\n",
    "                    \n",
    "shearbandswarm.update_particle_owners()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<underworld.utils._utils.SavedFileData at 0x7f76c69bcf50>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shearbandswarm.save(filePath + 'swarm.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#shearbandswarm.particleCoordinates.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and save some metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We'll create a function that based on the strain rate 2-sigma value. \n",
    "#Use this to estimate thickness and average pressure within the shear band\n",
    "\n",
    "conds = [ ( (strainRate_2ndInvariantFn >  eII_sig) & (coord[1] > ndp.asthenosphere + ndp.notchWidth), 1.),\n",
    "            (                                           True , 0.) ]\n",
    "\n",
    "\n",
    "conds2 = [ ( (strainRate_2ndInvariantFn <  eII_sig) & (coord[1] > ndp.asthenosphere + ndp.notchWidth), 1.),\n",
    "            (                                           True , 0.) ]\n",
    "\n",
    "\n",
    "# lets also integrate just one eighth of sphere surface\n",
    "_2sigRest= fn.branching.conditional( conds ) \n",
    "\n",
    "_out2sigRest= fn.branching.conditional( conds2 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqrtv2 = fn.math.sqrt(fn.math.dot(velocityField,velocityField))\n",
    "#sqrtv2x = fn.math.sqrt(fn.math.dot(velocityField[0],velocityField[0]))\n",
    "vd = 4.*viscosityFn*strainRate_2ndInvariantFn # there's an extra factor of 2, which is necessary because the of factor of 0.5 in the UW second invariant \n",
    "\n",
    "\n",
    "_rmsint = uw.utils.Integral(sqrtv2, mesh)\n",
    "\n",
    "#_rmsSurf = uw.utils.Integral(sqrtv2x, mesh, integrationType='Surface',surfaceIndexSet=mesh.specialSets[\"MaxJ_VertexSet\"])\n",
    "\n",
    "_viscMM = fn.view.min_max(viscosityFn)\n",
    "dummyFn = _viscMM.evaluate(swarm)\n",
    "\n",
    "_eiiMM = fn.view.min_max(strainRate_2ndInvariantFn)\n",
    "dummyFn = _eiiMM.evaluate(swarm)\n",
    "\n",
    "#Area and pressure integrals inside / outside shear band\n",
    "\n",
    "_shearArea = uw.utils.Integral(_2sigRest, mesh)\n",
    "_shearPressure = uw.utils.Integral(_2sigRest*pressureField, mesh)\n",
    "\n",
    "_backgroundArea = uw.utils.Integral(_out2sigRest, mesh)\n",
    "_backgroundPressure = uw.utils.Integral(_out2sigRest*pressureField, mesh)\n",
    "\n",
    "#dissipation \n",
    "\n",
    "_vdint  = uw.utils.Integral(vd,mesh)\n",
    "_shearVd  = uw.utils.Integral(vd*_2sigRest,mesh)\n",
    "_backgroundVd  = uw.utils.Integral(vd*_out2sigRest,mesh)\n",
    "\n",
    "#dynamic pressure min / max\n",
    "\n",
    "_press = fn.view.min_max(pressureField)\n",
    "dummyFn = _press.evaluate(swarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#_viscMM.min_global(), _viscMM.max_global()\n",
    "#_eiiMM.min_global(), _eiiMM.max_global()\n",
    "\n",
    "rmsint = _rmsint.evaluate()[0]\n",
    "\n",
    "shearArea = _shearArea.evaluate()[0]\n",
    "shearPressure = _shearPressure.evaluate()[0]\n",
    "\n",
    "backgroundArea = _backgroundArea.evaluate()[0]\n",
    "backgroundPressure = _backgroundPressure.evaluate()[0]\n",
    "\n",
    "vdint = _vdint.evaluate()[0]\n",
    "shearVd = _shearVd.evaluate()[0]\n",
    "backgroundVd = _backgroundVd.evaluate()[0]\n",
    "\n",
    "\n",
    "viscmin = _viscMM.min_global()\n",
    "viscmax = _viscMM.max_global()\n",
    "eiimin = _eiiMM.min_global()\n",
    "eiimax = _eiiMM.max_global()\n",
    "\n",
    "pressmax = _press.max_global()\n",
    "pressmin = _press.min_global()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.72691599039378241, 0.31399643861919457)\n"
     ]
    }
   ],
   "source": [
    "fname = filePath + 'swarm.h5'\n",
    "\n",
    "if uw.rank()==0:\n",
    "    with h5py.File(fname,'r') as hf:\n",
    "        #print('List of arrays in this file: \\n', hf.keys())\n",
    "        data = hf.get('data')\n",
    "        np_data = np.array(data)\n",
    "\n",
    "    sbx =  np_data[:,0]\n",
    "    sby =  np_data[:,1]\n",
    "\n",
    "    #sbx =  shearbandswarm.particleCoordinates.data[:,0]\n",
    "    #sby =  shearbandswarm.particleCoordinates.data[:,1]\n",
    "\n",
    "    z = np.polyfit(sbx, sby, 1)\n",
    "    p = np.poly1d(z)\n",
    "    \n",
    "    #newcoords = np.column_stack((sbx, p(sbx)))\n",
    "    angle = math.atan(z[0])*(180./math.pi)\n",
    "    45. - dp.fa\n",
    "    \n",
    "comm.barrier()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if rank==0:\n",
    "    dydx = p[1]\n",
    "    const = p[0]\n",
    "else:\n",
    "    dydx = 1.\n",
    "    const = 0.\n",
    "\n",
    "# share value of dydx\n",
    "comm.barrier()\n",
    "dydx = comm.bcast(dydx, root = 0)\n",
    "const = comm.bcast(const, root = 0)\n",
    "comm.barrier()\n",
    "\n",
    "\n",
    "\n",
    "print(dydx, const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "       85, 86, 87, 88, 89, 90, 91, 92, 93, -1, -1, -1, -1, -1, -1], dtype=int32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = np.linspace(0, -1., 100)\n",
    "newcoords = np.column_stack((xs, dydx*xs + const )) \n",
    "\n",
    "\n",
    "swarmCustom = uw.swarm.Swarm(mesh)\n",
    "swarmCustom.add_particles_with_coordinates(newcoords )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results/T/0/images/figTest2.png'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figTest2 = glucifer.Figure( figsize=(1600,400), boundingBox=((-2.0, 0.0, 0.0), (2.0, 1.0, 0.0)) )\n",
    "figTest2.append( glucifer.objects.Points(shearbandswarm, pointSize=2.0, colourBar=False) )\n",
    "\n",
    "figTest2.append( glucifer.objects.Points(swarmCustom , pointSize=4.0,colourBar=False) )\n",
    "\n",
    "figTest2.append( glucifer.objects.Points(swarm,strainRate_2ndInvariantFn, pointSize=3.0, valueRange=[1e-3, 1.5]) )\n",
    "\n",
    "#figTest2.show()\n",
    "\n",
    "figTest2.save_image(imagePath +  \"figTest2.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "if uw.rank()==0:\n",
    "\n",
    "    someVals = [rmsint, shearArea ,shearPressure, \n",
    "                backgroundArea, backgroundPressure, viscmin, viscmax, eiimin, eiimax, angle,vdint, shearVd, backgroundVd, pressmin, pressmax  ] \n",
    "\n",
    "    with open(os.path.join(outputPath, 'metrics.csv'), 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=\",\")\n",
    "        writer.writerow(someVals)\n",
    "    with open(os.path.join(outputPath, 'solver.csv'), 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=\",\")\n",
    "        writer.writerow(res1Vals)\n",
    "        writer.writerow(res2Vals)\n",
    "        writer.writerow(res3Vals)\n",
    "    with open(os.path.join(outputPath, 'params.csv'), 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=\",\")\n",
    "        writer.writerow([dp[i] for i in sorted(dp.keys())]) #this makes sure the params are written in order of the sorted keys (i.e an order we can reproduce)\n",
    "        writer.writerow([ndp[i] for i in sorted(ndp.keys())])\n",
    "        writer.writerow([md[i] for i in sorted(md.keys())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "test = np.array([0.5, 0.5])\n",
    "\n",
    "ys = np.linspace(0, 1, 10)\n",
    "xs = np.zeros(10)\n",
    "\n",
    "points = np.column_stack((xs, ys))\n",
    "\n",
    "\n",
    "ix, weights = nn_evaluation(swarm, points, n=1, weighted=False)\n",
    "ix, weights\n",
    "\n",
    "visc = viscosityFn.evaluate(swarm)[ix]\n",
    "\n",
    "\n",
    "%pylab inline\n",
    "plt.scatter(ys, visc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sorted(dp.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sorted(ndp.keys()) == sorted(dp.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
